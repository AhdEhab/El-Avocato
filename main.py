import streamlit as st
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain import PromptTemplate, LLMChain
import os
from dotenv import load_dotenv
import faiss

# -------- Load API Token --------
load_dotenv()
token = os.getenv("GOOGLE_API_KEY")

# -------- Embeddings --------
@st.cache_resource
def load_embeddings():
    return HuggingFaceEmbeddings(
        model_name="intfloat/multilingual-e5-large-instruct",
        encode_kwargs={"device": "cpu"}
    )

embeddings = load_embeddings()

# -------- Load FAISS Indexes --------
constitutional_index = FAISS.load_local(
    "indexes/faiss_constitutional_index", embeddings, allow_dangerous_deserialization=True
)
statutory_index = FAISS.load_local(
    "indexes/faiss_statutory_index", embeddings, allow_dangerous_deserialization=True
)

# -------- Retrieval --------
def retrieve_docs(index, query, k=5, score_threshold=0.4):
    docs_with_scores = index.similarity_search_with_score(query, k=k)
    results = []
    for doc, score in docs_with_scores:
        if score <= score_threshold:  
            results.append({
                "text": doc.page_content,
                "metadata": doc.metadata
            })
    if not results:
        return [{"text": "No relevant result.", "metadata": {}}]
    return results


# -------- reversed numbers --------
import re
def fix_years(text: str) -> str:
    def replace_year(match):
        year = match.group()
        # Ù…Ø«Ø§Ù„: 3002 -> 2003
        if year.startswith("3") or year.startswith("0"):
            return year[::-1]  # Ù‚Ù„Ø¨ Ø§Ù„Ø±Ù‚Ù…
        return year
    return re.sub(r"\b\d{4}\b", replace_year, text)

# -------- Prompt Template --------
template = """
Ø§Ù†Øª Ù†Ø¸Ø§Ù… Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ù…ØµØ±ÙŠ. ÙŠØ¬Ø¨ Ø£Ù† ØªØ¨Ù†ÙŠ Ø¥Ø¬Ø§Ø¨ØªÙƒ Ø¹Ù„Ù‰ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø§Ù„Ù…ØªØ§Ø­Ø© ÙÙ‚Ø·.

Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª:
- Ù„Ø§ ØªØ¹ÙŠØ¯ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø£ØµÙ„ÙŠØ© ÙƒÙ…Ø§ Ù‡ÙŠ.
- Ø£Ø¬Ø¨ Ø¨ØµÙŠØ§ØºØ© Ù…Ø¨Ø§Ø´Ø±Ø© Ù‚Ø¯ Ø§Ù„Ø³Ø¤Ø§Ù„ ÙÙ‚Ø·.
- Ø§Ø°ÙƒØ± Ø±Ù‚Ù… Ø§Ù„Ù…Ø§Ø¯Ø© + Ù…ØµØ¯Ø±Ù‡Ø§ Ø¯Ø§Ø®Ù„ Ø§Ù„Ø¬Ù…Ù„Ø© (Ù…Ø«Ø§Ù„: "ÙˆÙÙ‚Ù‹Ø§ Ù„Ù„Ù…Ø§Ø¯Ø© 244 Ù…Ù† Ù‚Ø§Ù†ÙˆÙ† Ø§Ù„Ø¹Ù‚ÙˆØ¨Ø§Øª").
- Ø¥Ø°Ø§ ÙˆØ¬Ø¯Øª Ø£ÙƒØ«Ø± Ù…Ù† Ù…Ø§Ø¯Ø© Ù…Ø±ØªØ¨Ø·Ø©ØŒ Ø§Ø¯Ù…Ø¬Ù‡Ø§ Ø¨Ø´ÙƒÙ„ Ù…Ù†Ø¸Ù….
- Ø¥Ø°Ø§ Ù„Ù… ÙŠÙˆØ¬Ø¯ Ù†Øµ Ù…Ù†Ø§Ø³Ø¨ØŒ Ø§ÙƒØªØ¨ (Ù„Ø§ ØªÙˆØ¬Ø¯ Ù†ØªÙŠØ¬Ø© Ù…Ø±ØªØ¨Ø·Ø©).

Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø§Ù„Ù…ØªØ§Ø­Ø© (Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠ ÙÙ‚Ø·):
{context}

Ø§Ù„Ø³Ø¤Ø§Ù„: {query}

Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:
"""

llm = ChatGoogleGenerativeAI(
    model="gemma-3-4b-it",
    google_api_key=token
)

prompt = PromptTemplate(
    template=template,
    input_variables=["context", "query"]
)

llm_chain = LLMChain(
    prompt=prompt,
    llm=llm,
)

# -------- Query Function --------
def query_legal_assistant(query):
    constitutional_hits = retrieve_docs(constitutional_index, query, k=5, score_threshold=0.7)
    statutory_hits = retrieve_docs(statutory_index, query, k=5, score_threshold=0.7)

    def format_hits(hits, label, ref_key="article_number"):
        formatted = []
        for h in hits:
            meta = h["metadata"]
            ref = meta.get(ref_key, meta.get("page", "ØºÙŠØ± Ù…ØªÙˆÙØ±"))
            formatted.append(
                f"{label} - Ø§Ù„Ù…Ø§Ø¯Ø© {ref}:\n{h['text']}\n(Ø§Ù„Ù…ØµØ¯Ø±: {meta.get('source')})"
            )
        return "\n\n".join(formatted) if formatted else f"{label}: (Ù„Ø§ ØªÙˆØ¬Ø¯ Ù†ØªÙŠØ¬Ø© Ù…Ø±ØªØ¨Ø·Ø©)"

    context = "\n\n".join([
        format_hits(constitutional_hits, "Ø§Ù„Ø¯Ø³ØªÙˆØ±"),
        format_hits(statutory_hits, "Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†"),
    ])

    response = llm_chain.run({"context": context, "query": query})
    response = fix_years(response)
    return response

# -------- Streamlit UI --------
st.set_page_config(page_title="Legal AI Assistant", page_icon="âš–ï¸", layout="wide")

st.image("D:\Digitopia\App\logo.jpg", width=250) 
st.write("Ø§Ø³Ø£Ù„ Ø³Ø¤Ø§Ù„Ø§Ù‹ Ù‚Ø§Ù†ÙˆÙ†ÙŠØ§Ù‹ ÙˆØ³ÙŠØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¯Ø³ØªÙˆØ±ÙŠØ© ÙˆØ§Ù„ØªØ´Ø±ÙŠØ¹ÙŠØ© Ø°Ø§Øª Ø§Ù„ØµÙ„Ø©.")

query = st.text_area("ğŸ“ Ø£Ø¯Ø®Ù„ Ø³Ø¤Ø§Ù„Ùƒ:", placeholder="Ù…Ø«Ø§Ù„: Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ù„ØªÙ‚Ø¯ÙŠÙ… Ø·Ù„Ø¨ Ø¥Ø®Ù„Ø§Ø¡ Ø³Ø¨ÙŠÙ„ Ù…ØªÙ‡Ù…ØŸ")

if st.button("Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…"):
    if query.strip():
        with st.spinner("â³ Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø¨Ø­Ø« ÙˆØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©..."):
            answer = query_legal_assistant(query)

        st.subheader(" Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:")
        st.write(answer)
    else:
        st.warning("âš ï¸ Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ Ø³Ø¤Ø§Ù„ Ø£ÙˆÙ„Ø§Ù‹.")
