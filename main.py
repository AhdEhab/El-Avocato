import streamlit as st
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain import PromptTemplate, LLMChain
import os
from dotenv import load_dotenv

# -------- Load API Token --------
load_dotenv()
token = os.getenv("GOOGLE_API_KEY")

# -------- Embeddings --------
embeddings = HuggingFaceEmbeddings(model_name="intfloat/multilingual-e5-large-instruct")

# -------- Load FAISS Indexes --------
constitutional_index = FAISS.load_local(
    "indexes/faiss_constitutional_index", embeddings, allow_dangerous_deserialization=True
)
statutory_index = FAISS.load_local(
    "indexes/faiss_statutory_index", embeddings, allow_dangerous_deserialization=True
)

# -------- Retrieval (Ø¨Ø¯ÙˆÙ† threshold) --------
def retrieve_docs(index, query, k=5):
    docs = index.similarity_search("query: " + query, k=k)
    results = []
    for doc in docs:
        results.append({
            "text": doc.page_content,
            "metadata": doc.metadata
        })
    if not results:
        return [{"text": "No relevant result.", "metadata": {}}]
    return results

# -------- Prompt Template --------
template = """
Ø§Ù†Øª Ù†Ø¸Ø§Ù… Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ù…ØµØ±ÙŠ. ÙŠØ¬Ø¨ Ø£Ù† ØªØ¨Ù†ÙŠ Ø¥Ø¬Ø§Ø¨ØªÙƒ Ø¹Ù„Ù‰ Ø·Ø¨Ù‚ØªÙŠÙ† Ù…ØªØ±Ø§Ø¨Ø·ØªÙŠÙ† Ù‡Ø±Ù…ÙŠØ§Ù‹:
1. Ø§Ù„Ø¯Ø³ØªÙˆØ± (Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¹Ù„ÙŠØ§) â†’ ÙŠØ¶Ø¹ Ø§Ù„Ù…Ø¨Ø§Ø¯Ø¦ Ø§Ù„Ø¹Ø§Ù…Ø©.
2. Ø§Ù„ØªØ´Ø±ÙŠØ¹Ø§Øª (Ø§Ù„Ù‚ÙˆØ§Ù†ÙŠÙ† Ø§Ù„Ù…ÙØ³Ø±Ø©) â†’ ØªØ³ØªÙ†Ø¯ Ø¥Ù„Ù‰ Ø§Ù„Ø¯Ø³ØªÙˆØ± ÙˆØªÙØ³Ø± Ù…ÙˆØ§Ø¯Ù‡.

Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª:
- Ø§Ø¹Ø±Ø¶ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¯Ø³ØªÙˆØ±ÙŠØ© Ø£ÙˆÙ„Ø§Ù‹ Ø¥Ù† ÙˆÙØ¬Ø¯Øª.
- Ø«Ù… Ø§Ø¹Ø±Ø¶ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„ØªØ´Ø±ÙŠØ¹ÙŠØ© Ø§Ù„Ù…Ø±ØªØ¨Ø·Ø© Ø¨Ù‡Ø§.
- Ù„ÙƒÙ„ Ø¬Ø²Ø¡ØŒ Ø§Ø°ÙƒØ± Ø§Ù„Ù†Øµ ÙƒØ§Ù…Ù„Ø§Ù‹ Ù…Ø¹ Ø§Ù„Ù…ØµØ¯Ø± ÙˆØ±Ù‚Ù… Ø§Ù„Ù…Ø§Ø¯Ø© Ù…Ù† Ø§Ù„Ù€ metadata.
- Ø¥Ø°Ø§ Ù„Ù… ÙŠÙˆØ¬Ø¯ Ù†Øµ ÙÙŠ Ø·Ø¨Ù‚Ø© Ù…Ø¹ÙŠÙ†Ø©ØŒ Ø§ÙƒØªØ¨ (Ù„Ø§ ØªÙˆØ¬Ø¯ Ù†ØªÙŠØ¬Ø© Ù…Ø±ØªØ¨Ø·Ø©).
- Ù„Ø§ ØªØ¶Ù Ø£ÙŠ Ù†Øµ Ø£Ùˆ ØªÙØ³ÙŠØ± ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.

Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ (Ù…Ø±ØªÙ‘Ø¨ ÙˆÙ…ØªØ±Ø§Ø¨Ø· ÙˆÙ„ÙŠØ³ Ù…Ù‚Ø§Ø·Ø¹ Ù…Ù†ÙØµÙ„Ø©):
{context}

Ø§Ù„Ø³Ø¤Ø§Ù„: {query}

Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:
"""

llm = ChatGoogleGenerativeAI(
    model="gemma-3-4b-it",
    google_api_key=token
)

prompt = PromptTemplate(
    template=template,
    input_variables=["context", "query"]
)

llm_chain = LLMChain(
    prompt=prompt,
    llm=llm,
)

# -------- Query Function --------
def query_legal_assistant(query):
    constitutional_hits = retrieve_docs(constitutional_index, query, k=5)
    statutory_hits = retrieve_docs(statutory_index, query, k=5)

    def format_hits(hits, label, ref_key="article_number"):
        if hits and hits[0]["text"] != "No relevant result.":
            formatted = []
            for h in hits:
                meta = h["metadata"]
                ref = meta.get(ref_key, meta.get("page", "ØºÙŠØ± Ù…ØªÙˆÙØ±"))
                formatted.append(
                    f"Ø§Ù„Ù†Øµ: {h['text']}\n"
                    f"Ø§Ù„Ù…ØµØ¯Ø±: {meta.get('source')}, Ø§Ù„Ù…Ø±Ø¬Ø¹: {ref}"
                )
            return f"## {label}\n" + "\n\n".join(formatted)
        else:
            return f"## {label}\n(Ù„Ø§ ØªÙˆØ¬Ø¯ Ù†ØªÙŠØ¬Ø© Ù…Ø±ØªØ¨Ø·Ø©)"

    context = "\n\n".join([
        format_hits(constitutional_hits, "Ø§Ù„Ø¯Ø³ØªÙˆØ± (Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¹Ù„ÙŠØ§)", "article_number"),
        format_hits(statutory_hits, "Ø§Ù„ØªØ´Ø±ÙŠØ¹Ø§Øª (Ø§Ù„Ù‚ÙˆØ§Ù†ÙŠÙ† Ø§Ù„Ù…ÙØ³Ø±Ø©)", "article_number"),
    ])

    response = llm_chain.run({"context": context, "query": query})
    return response, context


# -------- Streamlit UI --------
st.set_page_config(page_title="Legal AI Assistant", page_icon="âš–ï¸", layout="wide")

st.title("âš–ï¸ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø§Ù„Ù…ØµØ±ÙŠ")
st.write("Ø§Ø³Ø£Ù„ Ø³Ø¤Ø§Ù„Ø§Ù‹ Ù‚Ø§Ù†ÙˆÙ†ÙŠØ§Ù‹ ÙˆØ³ÙŠØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¯Ø³ØªÙˆØ±ÙŠØ© ÙˆØ§Ù„ØªØ´Ø±ÙŠØ¹ÙŠØ© Ø°Ø§Øª Ø§Ù„ØµÙ„Ø©.")

query = st.text_area("ğŸ“ Ø£Ø¯Ø®Ù„ Ø³Ø¤Ø§Ù„Ùƒ:", placeholder="Ù…Ø«Ø§Ù„: Ù…Ø§ Ù‡ÙŠ Ø­Ù‚ÙˆÙ‚ Ø­Ø±ÙŠØ© Ø§Ù„ØªØ¹Ø¨ÙŠØ± ÙÙŠ Ø§Ù„Ø¯Ø³ØªÙˆØ± Ø§Ù„Ù…ØµØ±ÙŠØŸ")

if st.button("Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…"):
    if query.strip():
        with st.spinner("â³ Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø¨Ø­Ø« ÙˆØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©..."):
            answer, context = query_legal_assistant(query)

        st.subheader("ğŸ“Œ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:")
        st.write(answer)

        with st.expander("ğŸ“‚ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… (Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ø³ØªØ±Ø¬Ø¹Ø©)"):
            st.markdown(context)
    else:
        st.warning("âš ï¸ Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ Ø³Ø¤Ø§Ù„ Ø£ÙˆÙ„Ø§Ù‹.")

